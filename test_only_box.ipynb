{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a7d1021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# Load your trained model\n",
    "model = YOLO(r'E:\\elevatetrsest\\CamEDGE counting\\bestv2.pt') # Use your model path\n",
    "\n",
    "# Define the classes your model was trained on\n",
    "# CLASSES = ['box', 'box_broken', 'open_package', 'package']  #for best_only_box.pt\n",
    "CLASSES = ['box', 'box_broken', 'forklift', 'open_package', 'package', 'pallets', 'person'] #bestv2.pt\n",
    "CLASS_TO_TRACK_EXCLUSIVELY = 'box' \n",
    "\n",
    "# For managing our own sequential box IDs\n",
    "box_id_map = {}  # Maps original tracker ID of a box to our sequential display ID\n",
    "next_display_box_id = 1 # Counter for our sequential display IDs\n",
    "\n",
    "def detect_and_custom_track_video(video_path, output_path=None, conf_threshold=0.5, tracker_config=\"bytetrack.yaml\"):\n",
    "    \"\"\"\n",
    "    Detect all objects, display sequential track IDs only for the 'box' class.\n",
    "    Counts all objects per frame and unique 'box' instances using custom IDs.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to input video\n",
    "        output_path: Path to save output video (optional)\n",
    "        conf_threshold: Confidence threshold for detections\n",
    "        tracker_config: Path to the tracker configuration file\n",
    "    \"\"\"\n",
    "    global box_id_map, next_display_box_id # Use global for map and counter\n",
    "    box_id_map.clear() # Clear for fresh run if function is called multiple times\n",
    "    next_display_box_id = 1\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    writer = None\n",
    "\n",
    "    if output_path:\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    frame_count = 0\n",
    "    # For counting all object types per frame\n",
    "    current_frame_object_counts = {class_name: 0 for class_name in CLASSES}\n",
    "    # For overall summary of any object detected at least once\n",
    "    overall_objects_summary = {class_name: 0 for class_name in CLASSES}\n",
    "    overall_seen_tracker_ids = set() # Uses the tracker's original IDs for this summary\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"End of video or error reading frame.\")\n",
    "            break\n",
    "        frame_count += 1\n",
    "        annotated_frame = frame.copy()\n",
    "\n",
    "        results = model.track(frame, conf=conf_threshold, persist=True, tracker=tracker_config, verbose=False)\n",
    "\n",
    "        current_frame_object_counts = {class_name: 0 for class_name in CLASSES}\n",
    "\n",
    "        if results[0].boxes is not None:\n",
    "            boxes_data = results[0].boxes.xyxy.cpu().numpy()\n",
    "            confs_data = results[0].boxes.conf.cpu().numpy()\n",
    "            class_ids_data = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "            \n",
    "            original_tracker_ids_data = None\n",
    "            if results[0].boxes.id is not None:\n",
    "                original_tracker_ids_data = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "\n",
    "            for i in range(len(boxes_data)):\n",
    "                x1, y1, x2, y2 = map(int, boxes_data[i])\n",
    "                conf = confs_data[i]\n",
    "                class_id = class_ids_data[i]\n",
    "                class_name = model.names[class_id]\n",
    "\n",
    "                current_frame_object_counts[class_name] += 1\n",
    "                \n",
    "                label = f\"{class_name} {conf:.2f}\"\n",
    "                display_id_for_this_box = None\n",
    "\n",
    "                if original_tracker_ids_data is not None:\n",
    "                    original_tracker_id = original_tracker_ids_data[i]\n",
    "\n",
    "                    # Update overall summary (counts any tracked object once using original ID)\n",
    "                    if original_tracker_id not in overall_seen_tracker_ids:\n",
    "                        overall_objects_summary[class_name] = overall_objects_summary.get(class_name, 0) + 1\n",
    "                        overall_seen_tracker_ids.add(original_tracker_id)\n",
    "\n",
    "                    if class_name == CLASS_TO_TRACK_EXCLUSIVELY:\n",
    "                        if original_tracker_id not in box_id_map:\n",
    "                            box_id_map[original_tracker_id] = next_display_box_id\n",
    "                            next_display_box_id += 1\n",
    "                        display_id_for_this_box = box_id_map[original_tracker_id]\n",
    "                        label = f\"ID:{display_id_for_this_box} {class_name} {conf:.2f}\"\n",
    "\n",
    "                # --- Visuals: Bounding box for all ---\n",
    "                box_color = (0, 255, 0) # Default Green\n",
    "                if class_name == \"box_broken\": box_color = (0,0,255)\n",
    "                elif class_name == \"open_package\": box_color = (0,165,255)\n",
    "                elif class_name == \"forklift\": box_color = (255,0,0)\n",
    "                elif class_name == \"pallets\": box_color = (255,255,0)\n",
    "                elif class_name == \"person\": box_color = (128,0,128)\n",
    "                # No specific color for 'box' here as it's handled by default or its ID presence\n",
    "\n",
    "                cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), box_color, 2)\n",
    "                cv2.putText(annotated_frame, label, (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)\n",
    "        \n",
    "        y_offset = 30\n",
    "        cv2.putText(annotated_frame, f\"Frame: {frame_count}\",\n",
    "                    (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        y_offset += 25\n",
    "        for cls_name_txt, count_txt in current_frame_object_counts.items():\n",
    "            if count_txt > 0:\n",
    "                cv2.putText(annotated_frame, f\"{cls_name_txt}: {count_txt}\",\n",
    "                            (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "                y_offset += 25\n",
    "\n",
    "        if writer:\n",
    "            writer.write(annotated_frame)\n",
    "\n",
    "        cv2.imshow(f'Warehouse Tracking (Sequential IDs for \"{CLASS_TO_TRACK_EXCLUSIVELY}\")', annotated_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        if frame_count % 100 == 0:\n",
    "            # next_display_box_id is 1 more than the highest ID assigned\n",
    "            unique_box_display_count = next_display_box_id -1 if next_display_box_id > 1 else 0\n",
    "            print(f\"Processed {frame_count} frames. Unique '{CLASS_TO_TRACK_EXCLUSIVELY}' display count: {unique_box_display_count}. Current frame counts: {current_frame_object_counts}\")\n",
    "\n",
    "    cap.release()\n",
    "    if writer:\n",
    "        writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    total_unique_display_boxes = next_display_box_id - 1 if next_display_box_id > 1 else 0\n",
    "\n",
    "    print(f\"\\n🎉 Video processing complete!\")\n",
    "    print(f\"📝 Total frames processed: {frame_count}\")\n",
    "    print(f\"📦 Total unique '{CLASS_TO_TRACK_EXCLUSIVELY}' objects (with sequential display IDs): {total_unique_display_boxes}\")\n",
    "    # print(f\"📊 Overall summary of unique objects (any class with original tracker ID) detected: {overall_objects_summary}\") # Optional\n",
    "    \n",
    "    return total_unique_display_boxes, overall_objects_summary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ed493b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Warehouse Video Detection (Custom Sequential Tracking for 'box') System Ready!\n",
      "\n",
      "Processing video: E:\\elevatetrsest\\CamEDGE counting\\test\\test9_warehouse.mp4\n",
      "Processed 100 frames. Unique 'box' display count: 5. Current frame counts: {'box': 3, 'box_broken': 0, 'forklift': 0, 'open_package': 0, 'package': 0, 'pallets': 0, 'person': 0}\n",
      "Processed 200 frames. Unique 'box' display count: 8. Current frame counts: {'box': 2, 'box_broken': 0, 'forklift': 0, 'open_package': 0, 'package': 0, 'pallets': 0, 'person': 0}\n",
      "Processed 300 frames. Unique 'box' display count: 14. Current frame counts: {'box': 2, 'box_broken': 0, 'forklift': 0, 'open_package': 0, 'package': 0, 'pallets': 0, 'person': 0}\n",
      "Processed 400 frames. Unique 'box' display count: 17. Current frame counts: {'box': 2, 'box_broken': 0, 'forklift': 0, 'open_package': 0, 'package': 0, 'pallets': 0, 'person': 0}\n",
      "Processed 500 frames. Unique 'box' display count: 19. Current frame counts: {'box': 1, 'box_broken': 0, 'forklift': 0, 'open_package': 0, 'package': 0, 'pallets': 0, 'person': 0}\n",
      "End of video or error reading frame.\n",
      "\n",
      "🎉 Video processing complete!\n",
      "📝 Total frames processed: 562\n",
      "📦 Total unique 'box' objects (with sequential display IDs): 19\n",
      "\n",
      "Final count of unique 'box' objects (with sequential display IDs): 19\n"
     ]
    }
   ],
   "source": [
    "# --- Usage Example ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"🚀 Warehouse Video Detection (Custom Sequential Tracking for '{CLASS_TO_TRACK_EXCLUSIVELY}') System Ready!\")\n",
    "    # --- CONFIGURE YOUR VIDEO PATH HERE ---\n",
    "    video_input_path = r\"E:\\elevatetrsest\\CamEDGE counting\\test\\test9_warehouse.mp4\"# REPLACE THIS\n",
    "    video_output_path = r'E:\\elevatetrsest\\CamEDGE counting\\tracking_output\\output9.mp4' # REPLACE THIS (OPTIONAL)\n",
    "\n",
    "    if video_input_path == r'path_to_your_warehouse_video.mp4':\n",
    "        print(\"\\n⚠️ PLEASE UPDATE 'video_input_path' in the script with your actual video file path.\")\n",
    "    else:\n",
    "        try:\n",
    "            print(f\"\\nProcessing video: {video_input_path}\")\n",
    "            # Example: Process and display only\n",
    "            unique_boxes_display_count, _ = detect_and_custom_track_video(video_input_path, conf_threshold=0.6)\n",
    "            # Example: Process and save\n",
    "            # unique_boxes_display_count, _ = detect_and_custom_track_video(video_input_path, video_output_path, conf_threshold=0.4)\n",
    "            \n",
    "            print(f\"\\nFinal count of unique '{CLASS_TO_TRACK_EXCLUSIVELY}' objects (with sequential display IDs): {unique_boxes_display_count}\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: Video file not found at '{video_input_path}'. Please check the path.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Ensure your video path is correct and OpenCV and Ultralytics are installed properly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a860b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
